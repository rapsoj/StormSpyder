{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06249019-8d5a-4862-a17c-874855663bbe",
   "metadata": {},
   "source": [
    "![title](title-card.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051ca79-74d1-4936-a70b-4bdb6d05a955",
   "metadata": {},
   "source": [
    "### Prepare Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769f85c5-d455-4797-ac92-479c0d48a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load system libraries\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# Load web-scraping libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "# Load data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load image manipulation libraries\n",
    "from PIL import Image\n",
    "from scipy.ndimage import label\n",
    "from scipy.spatial.distance import cdist\n",
    "import rasterio\n",
    "\n",
    "# Load geospatial libraries\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "\n",
    "# Load machine learning libraries\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Load email libraries\n",
    "import yagmail\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc46ac4e-e6fe-49f0-995a-41d27a7facf3",
   "metadata": {},
   "source": [
    "### Scrape ECMWF Tropical Storm Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc23eb0f-7b53-46dc-9228-826ffd969d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to download images from ECMWF website\n",
    "def download_images(storm_type):\n",
    "\n",
    "    # Path to the directory where you want to save the images\n",
    "    save_dir = \"temp/\" + storm_type\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # URL of the website\n",
    "    url = \"https://charts.ecmwf.int/products/medium-tc-genesis\"\n",
    "    \n",
    "    # XPaths for the relevant interactions\n",
    "    dimensions_xpath = '//span[contains(text(), \"Select dimensions\")]'\n",
    "    dropdown_xpath = '//div[@id=\"mui-component-select-layer_name\"]'\n",
    "    storm_type_xpath_template = '//li[@class=\"MuiButtonBase-root MuiListItem-root MuiMenuItem-root MuiMenuItem-gutters MuiListItem-gutters MuiListItem-button\" and @data-value=\"{}\"]'\n",
    "    close_xpath = '//span[@class=\"MuiButton-label\" and text()=\"Close\"]'\n",
    "    image_xpath_template = '//*[@id=\"root\"]/div/div/div/div[3]/div/div[2]/div[1]/div/div/div/div[2]/img[{}]'\n",
    "    next_button_xpath = '//*[@id=\"root\"]/div/div/div/div[3]/div/div[2]/div[1]/div/div/div/div[3]/div[2]/div/button[4]'\n",
    "    \n",
    "    # Initialize the webdriver\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    if storm_type != 'genesis_ts':\n",
    "        try:\n",
    "\n",
    "            # Wait for the dimensions button to be clickable and click it\n",
    "            select_dimensions_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, dimensions_xpath)))\n",
    "            select_dimensions_button.click()\n",
    "        \n",
    "            # Wait for the dropdown to be clickable and click it\n",
    "            dropdown = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, dropdown_xpath)))\n",
    "            dropdown.click()\n",
    "        \n",
    "            # Find and click on the storm type option\n",
    "            storm_type_xpath = storm_type_xpath_template.format(storm_type)\n",
    "            storm_type_element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, storm_type_xpath)))\n",
    "            storm_type_element.click()\n",
    "        \n",
    "            # Wait for the close button to be clickable and click it\n",
    "            close_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, close_xpath)))\n",
    "            close_button.click()\n",
    "    \n",
    "            # Wait for the page to load after selecting options\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, image_xpath_template.format(1))))\n",
    "    \n",
    "        except (TimeoutException, NoSuchElementException) as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            driver.quit()\n",
    "            raise\n",
    "    \n",
    "    # Loop to download each image\n",
    "    for i in range(1, 10):  # Assuming there are 9 images\n",
    "        try:\n",
    "            \n",
    "            # Construct the XPath for the current image\n",
    "            image_xpath = image_xpath_template.format(i)\n",
    "    \n",
    "            # Wait for the image element to be visible\n",
    "            image_element = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, image_xpath)))\n",
    "            \n",
    "            # Get the image source URL\n",
    "            image_url = image_element.get_attribute(\"src\")\n",
    "            \n",
    "            # Get the alt attribute of the image\n",
    "            alt_text = image_element.get_attribute(\"alt\")\n",
    "            \n",
    "            # Create a filename using the alt text\n",
    "            image_filename = os.path.join(save_dir, f\"{alt_text}.png\")\n",
    "            \n",
    "            # Download the image\n",
    "            image_path = os.path.join(save_dir, f\"{alt_text}.png\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(requests.get(image_url).content)\n",
    "            \n",
    "            # Click the next button\n",
    "            next_button = driver.find_element(By.XPATH, next_button_xpath)\n",
    "            next_button.click()\n",
    "            \n",
    "            # Wait for the page to load\n",
    "            time.sleep(1)\n",
    "\n",
    "        except (TimeoutException, NoSuchElementException) as e:\n",
    "            print(f\"An error occurred while processing image {i}: {e}\")\n",
    "            break\n",
    "        \n",
    "    # Close the webdriver\n",
    "    driver.quit()\n",
    "\n",
    "# Define function to get image paths\n",
    "def get_image_paths(storm_type):\n",
    "    folder_path = 'temp/' + storm_type\n",
    "\n",
    "    # Get list of all files and directories in the folder\n",
    "    all_items = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out directories, only keeping files\n",
    "    files = [f for f in all_items if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b85c0f-403e-4193-8bca-de860e70bf9a",
   "metadata": {},
   "source": [
    "### Detect Strike Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f424aed-edc7-49c3-98f4-519586e6f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert pixel indices to geospatial coordinates\n",
    "def pixel_to_geospatial(row, col, transform):\n",
    "    x, y = rasterio.transform.xy(transform, row, col)\n",
    "    return x, y\n",
    "\n",
    "# Define function to check colour similarity\n",
    "def is_similar_color(color1, color2, tolerance):\n",
    "    return np.linalg.norm(np.array(color1) - np.array(color2)) < tolerance\n",
    "\n",
    "# Define function to cluster points\n",
    "def cluster_points(geo_df):\n",
    "    if len(geo_df) > 0:\n",
    "        \n",
    "        # Convert spatial points into list\n",
    "        points = geo_df.geometry.apply(lambda geom: (geom.x, geom.y)).tolist()\n",
    "        \n",
    "        # Set the minimum distance\n",
    "        min_distance = 33392.607\n",
    "        \n",
    "        # Convert the GeoDataFrame points to a numpy array\n",
    "        points = np.array(geo_df.geometry.apply(lambda geom: (geom.x, geom.y)).tolist())\n",
    "        \n",
    "        # Define the epsilon parameter as ten times the minimum distance\n",
    "        epsilon = 5 * min_distance\n",
    "        \n",
    "        # Initialize DBSCAN clustering algorithm\n",
    "        dbscan = DBSCAN(eps=epsilon, min_samples=1)\n",
    "        \n",
    "        # Fit DBSCAN to the points\n",
    "        dbscan.fit(points)\n",
    "        \n",
    "        # Get labels assigned by DBSCAN\n",
    "        labels = dbscan.labels_\n",
    "        \n",
    "        # Add cluster labels to the GeoDataFrame\n",
    "        geo_df['cluster'] = labels\n",
    "        \n",
    "        # Count the number of points in each cluster\n",
    "        cluster_counts = geo_df['cluster'].value_counts()\n",
    "        \n",
    "        # Get the cluster IDs with at least four points\n",
    "        valid_clusters = cluster_counts[cluster_counts >= 4].index\n",
    "        \n",
    "        # Filter out points in clusters with less than four points\n",
    "        geo_df = geo_df[geo_df['cluster'].isin(valid_clusters)]\n",
    "\n",
    "        return geo_df\n",
    "\n",
    "# Create function to detect strike probabilities from downloaded images\n",
    "def detect_strike_probability(storm_type, date):\n",
    "\n",
    "    # Loop through strike probabilities using associated colours and colour tolerance\n",
    "    strike_probabilities = {0.1: (255,0,255,170), 0.2: (255,78,0,120), 0.3: (255,176,0,90), 0.4: (255,255,0,70), 0.5: (40,255,0,150),\n",
    "                            0.6: (0,140,47,50), 0.7: (2,255,255,100), 0.8: (2,127,254,50), 0.9: (0,0,255,50), 1.0: (122,16,178,20)}\n",
    "    \n",
    "    # Load the original map image\n",
    "    original_image = Image.open('temp/' + storm_type + '/' + date + '.png')\n",
    "    \n",
    "    # Convert the original image to numpy array\n",
    "    original_array = np.array(original_image)\n",
    "    \n",
    "    # Load the georeferenced TIF\n",
    "    georef_tif = 'ref_maps/georeferenced_map.tif'\n",
    "    dataset = rasterio.open(georef_tif)\n",
    "    \n",
    "    # Get the transform from the georeferenced TIF\n",
    "    transform = dataset.transform\n",
    "    \n",
    "    # Initialize an empty list to collect GeoDataFrames\n",
    "    geo_df_list = []\n",
    "    \n",
    "    # Loop through strike probabilities\n",
    "    for strike_prob in strike_probabilities.keys():\n",
    "        \n",
    "        # Define the strike probability target color and tolerance\n",
    "        target_color = strike_probabilities[strike_prob][:3]\n",
    "        color_tolerance = strike_probabilities[strike_prob][3]\n",
    "        \n",
    "        # Find the pixels that are similar to the target color\n",
    "        matching_pixels = np.zeros((original_array.shape[0], original_array.shape[1]), dtype=bool)\n",
    "        for row in range(original_array.shape[0]):\n",
    "            for col in range(original_array.shape[1]):\n",
    "                pixel_color = original_array[row, col, :3]\n",
    "                if is_similar_color(pixel_color, target_color, color_tolerance):\n",
    "                    matching_pixels[row, col] = True\n",
    "        \n",
    "        # Find the indices of the matching pixels\n",
    "        pixel_indices = np.argwhere(matching_pixels)\n",
    "        \n",
    "        # Convert pixel indices to geospatial coordinates\n",
    "        geospatial_points = [pixel_to_geospatial(row, col, transform) for row, col in pixel_indices]\n",
    "        \n",
    "        # Create a GeoDataFrame from the geospatial points\n",
    "        geometry = [Point(x, y) for x, y in geospatial_points]\n",
    "        geo_df_strike = gpd.GeoDataFrame(geometry=geometry, crs=dataset.crs)\n",
    "        \n",
    "        # Identify storm type and strike probability\n",
    "        geo_df_strike['type'] = storm_type\n",
    "        geo_df_strike['strike_probability'] = strike_prob\n",
    "    \n",
    "        # Append the current GeoDataFrame to the list\n",
    "        geo_df_list.append(geo_df_strike)\n",
    "    \n",
    "    # Concatenate all GeoDataFrames in the list into a single GeoDataFrame\n",
    "    geo_df = gpd.GeoDataFrame(pd.concat(geo_df_list, ignore_index=True), crs=dataset.crs)\n",
    "    \n",
    "    # Remove overlapping geometries by prioritising those with highest strike probability\n",
    "    geo_df = geo_df.sort_values(by=['geometry', 'strike_probability'], ascending=[True, False])\n",
    "    geo_df = geo_df.drop_duplicates(subset='geometry', keep='first')\n",
    "    geo_df = geo_df.reset_index(drop=True)\n",
    "\n",
    "    # Cluster points\n",
    "    geo_df = cluster_points(geo_df)\n",
    "\n",
    "    return geo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e44bf-5878-47c9-bacc-affa184b48ac",
   "metadata": {},
   "source": [
    "### Compare Storm Clusters With Population Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cedad1-5a0f-462a-a063-b7cfe85475d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to load population map\n",
    "def load_pop_map():\n",
    "    # Open the raster file\n",
    "    file_path = 'ref_maps/gpw_v4_population_count_rev11_2020_2pt5_min.tif'\n",
    "    with rasterio.open(file_path) as src:\n",
    "        # Read the raster data\n",
    "        pop_map = src.read(1)  # Read the first band\n",
    "        # Read the nodata value from metadata\n",
    "        nodata_value = src.nodata\n",
    "        # Get metadata\n",
    "        metadata = src.meta\n",
    "        # Get the coordinate reference system (CRS) of the raster\n",
    "        raster_crs = src.crs\n",
    "    \n",
    "    # Mask missing data from population map\n",
    "    missing_data_mask = np.isclose(pop_map, nodata_value)\n",
    "    \n",
    "    # Remove missing values from pop_map\n",
    "    pop_map = np.where(missing_data_mask, np.nan, pop_map)\n",
    "\n",
    "    return pop_map, src\n",
    "\n",
    "# Define function to load boundaries map\n",
    "def load_boundaries_map():\n",
    "    \n",
    "    # Read boundaries shapefile\n",
    "    boundaries = gpd.read_file('ref_maps/world-administrative-boundaries/world-administrative-boundaries.shp')\n",
    "    \n",
    "    # Reproject data to EPSG:4326\n",
    "    boundaries = boundaries.to_crs(epsg=4326)\n",
    "    \n",
    "    return boundaries\n",
    "\n",
    "# Define function to calculate expected impact\n",
    "def caclulate_impact(geo_df):\n",
    "\n",
    "    # Reproject data to EPSG:4326\n",
    "    geo_df = geo_df.to_crs(epsg=4326)\n",
    "    \n",
    "    # Initialise dataframe\n",
    "    df = pd.DataFrame({'regions': [], 'expected_impact': [], 'date': []})\n",
    "    \n",
    "    # Loop through storm clusters\n",
    "    for storm in geo_df['cluster'].unique():\n",
    "    \n",
    "        # Extract pixel values corresponding to points\n",
    "        storm_points = geo_df[geo_df['cluster'] == storm]\n",
    "        pixel_values = []\n",
    "        pixel_strike_prob = []\n",
    "        for index, point in storm_points.iterrows():\n",
    "            row, col = src.index(point.geometry.x, point.geometry.y)\n",
    "            if not np.isnan(pop_map[row, col]):\n",
    "                pixel_values.append(pop_map[row, col])\n",
    "                pixel_strike_prob.append(point['strike_probability'])\n",
    "        \n",
    "        # Get unique pixel values affected by storm\n",
    "        affected_pixels = np.unique(pixel_values)\n",
    "    \n",
    "        # Find which administrative regions are impacted by the storm\n",
    "        join_gdf = gpd.sjoin(storm_points, boundaries, how=\"inner\", predicate=\"within\")\n",
    "    \n",
    "        # Extract the unique administrative regions\n",
    "        unique_admin_regions = join_gdf['name'].unique()\n",
    "    \n",
    "        # Calculate expected impact\n",
    "        expected_impact = sum([pop * strike_prob for pop, strike_prob in zip(affected_pixels, pixel_strike_prob)])\n",
    "    \n",
    "        # Create a new DataFrame for the current storm\n",
    "        new_row = pd.DataFrame({'regions': [unique_admin_regions], 'expected_impact': [expected_impact], 'date': [date]})\n",
    "    \n",
    "        # Concatenate the new row to the existing DataFrame\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d25dfe-f6b3-4766-ae61-20b5bcfbb907",
   "metadata": {},
   "source": [
    "### Execute Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2679f07c-0dca-46e9-a17d-ce9c4e4cc104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:07\n",
      "Downloading tropical storm images...\n",
      "Detecting tropical storm strike probabilities for Sat 25 May 2024 12 UTC (T+96)\n",
      "Detecting tropical storm strike probabilities for Sun 26 May 2024 12 UTC (T+120)\n",
      "Detecting tropical storm strike probabilities for Sat 01 Jun 2024 12 UTC (T+264)\n",
      "Detecting tropical storm strike probabilities for Wed 29 May 2024 12 UTC (T+192)\n",
      "Detecting tropical storm strike probabilities for Tue 28 May 2024 12 UTC (T+168)\n",
      "Detecting tropical storm strike probabilities for Thu 30 May 2024 12 UTC (T+216)\n",
      "Detecting tropical storm strike probabilities for Fri 31 May 2024 12 UTC (T+240)\n",
      "Detecting tropical storm strike probabilities for Fri 24 May 2024 12 UTC (T+72)\n",
      "Detecting tropical storm strike probabilities for Mon 27 May 2024 12 UTC (T+144)\n",
      "21:04:20\n",
      "---------------------------------------------------------------------------------\n",
      "Downloading tropical cyclone images...\n",
      "Detecting tropical cyclone strike probabilities for Sat 25 May 2024 12 UTC (T+96)\n",
      "Detecting tropical cyclone strike probabilities for Sun 26 May 2024 12 UTC (T+120)\n",
      "Detecting tropical cyclone strike probabilities for Sat 01 Jun 2024 12 UTC (T+264)\n",
      "Detecting tropical cyclone strike probabilities for Wed 29 May 2024 12 UTC (T+192)\n",
      "Detecting tropical cyclone strike probabilities for Tue 28 May 2024 12 UTC (T+168)\n",
      "Detecting tropical cyclone strike probabilities for Thu 30 May 2024 12 UTC (T+216)\n",
      "Detecting tropical cyclone strike probabilities for Fri 31 May 2024 12 UTC (T+240)\n",
      "Detecting tropical cyclone strike probabilities for Fri 24 May 2024 12 UTC (T+72)\n",
      "Detecting tropical cyclone strike probabilities for Mon 27 May 2024 12 UTC (T+144)\n",
      "21:07:27\n",
      "---------------------------------------------------------------------------------\n",
      "Downloading hurricane images...\n",
      "Detecting hurricane strike probabilities for Sat 25 May 2024 12 UTC (T+96)\n",
      "Detecting hurricane strike probabilities for Sat 01 Jun 2024 12 UTC (T+264)\n",
      "Detecting hurricane strike probabilities for Wed 29 May 2024 12 UTC (T+192)\n",
      "Detecting hurricane strike probabilities for Tue 28 May 2024 12 UTC (T+168)\n",
      "Detecting hurricane strike probabilities for Thu 30 May 2024 12 UTC (T+216)\n",
      "Detecting hurricane strike probabilities for Fri 31 May 2024 12 UTC (T+240)\n",
      "Detecting hurricane strike probabilities for Fri 24 May 2024 12 UTC (T+72)\n",
      "21:09:54\n",
      "---------------------------------------------------------------------------------\n",
      "21:09:54\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now().time().strftime(\"%H:%M:%S\")) ### TO DELETE\n",
    "\n",
    "# Load reference maps\n",
    "pop_map, src = load_pop_map()\n",
    "boundaries = load_boundaries_map()\n",
    "\n",
    "# Initialise final dataframe\n",
    "df_all = pd.DataFrame({'regions': [], 'expected_impact': [], 'date': [], 'storm_type': []})\n",
    "\n",
    "# Delete temp folder if it exists\n",
    "if os.path.exists('temp') and os.path.isdir('temp'):\n",
    "    # Delete the folder and all its contents\n",
    "    shutil.rmtree('temp')\n",
    "\n",
    "# Loop through storm types\n",
    "storm_type_options = {'genesis_ts': 'tropical storm', 'genesis_td': 'tropical cyclone', 'genesis_hr': 'hurricane'}\n",
    "for storm_type in storm_type_options.keys():\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Downloading {storm_type_options[storm_type]} images...\")\n",
    "\n",
    "    # Download images from ECMWF website\n",
    "    download_images(storm_type)\n",
    "\n",
    "    # Loop through downloaded images\n",
    "    for file in get_image_paths(storm_type):\n",
    "\n",
    "        # Get date from file name\n",
    "        date = file[:-4]\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Detecting {storm_type_options[storm_type]} strike probabilities for {date}\")\n",
    "\n",
    "        # Detect strike probabilities for selected date\n",
    "        geo_df = detect_strike_probability(storm_type, date)\n",
    "\n",
    "        # Compare storm clusters with population map\n",
    "        if geo_df is not None:\n",
    "            df = caclulate_impact(geo_df)\n",
    "            df['storm_type'] = storm_type_options[storm_type]\n",
    "    \n",
    "            # Combine results into single dataframe\n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "    print(datetime.now().time().strftime(\"%H:%M:%S\")) ### TO DELETE\n",
    "    \n",
    "    # Print break\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "print(datetime.now().time().strftime(\"%H:%M:%S\")) ### TO DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464da11e-03c1-4ea8-af9f-3fb165fb9565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regions</th>\n",
       "      <th>expected_impact</th>\n",
       "      <th>date</th>\n",
       "      <th>storm_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Myanmar, India, Bangladesh]</td>\n",
       "      <td>1.025611e+06</td>\n",
       "      <td>Tue 28 May 2024 12 UTC (T+168)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[India, Bangladesh]</td>\n",
       "      <td>9.990156e+05</td>\n",
       "      <td>Wed 29 May 2024 12 UTC (T+192)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Myanmar, India, Bangladesh]</td>\n",
       "      <td>9.681755e+05</td>\n",
       "      <td>Mon 27 May 2024 12 UTC (T+144)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Myanmar, India, Bangladesh]</td>\n",
       "      <td>6.830140e+05</td>\n",
       "      <td>Sun 26 May 2024 12 UTC (T+120)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Venezuela, Colombia, Nicaragua, Costa Rica, P...</td>\n",
       "      <td>9.418765e+04</td>\n",
       "      <td>Sat 01 Jun 2024 12 UTC (T+264)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Venezuela, Colombia, Nicaragua, Costa Rica, P...</td>\n",
       "      <td>6.879827e+04</td>\n",
       "      <td>Fri 31 May 2024 12 UTC (T+240)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Venezuela, Colombia, Panama]</td>\n",
       "      <td>5.447357e+04</td>\n",
       "      <td>Tue 28 May 2024 12 UTC (T+168)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Japan]</td>\n",
       "      <td>4.102547e+04</td>\n",
       "      <td>Fri 31 May 2024 12 UTC (T+240)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Madagascar]</td>\n",
       "      <td>6.703489e+03</td>\n",
       "      <td>Sat 25 May 2024 12 UTC (T+96)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Japan]</td>\n",
       "      <td>3.346325e+03</td>\n",
       "      <td>Sat 01 Jun 2024 12 UTC (T+264)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Suriname]</td>\n",
       "      <td>2.039893e+00</td>\n",
       "      <td>Mon 27 May 2024 12 UTC (T+144)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Thu 30 May 2024 12 UTC (T+216)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Wed 29 May 2024 12 UTC (T+192)</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Fri 24 May 2024 12 UTC (T+72)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Sun 26 May 2024 12 UTC (T+120)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Wed 29 May 2024 12 UTC (T+192)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Sat 25 May 2024 12 UTC (T+96)</td>\n",
       "      <td>tropical cyclone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Fri 24 May 2024 12 UTC (T+72)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Thu 30 May 2024 12 UTC (T+216)</td>\n",
       "      <td>tropical storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Thu 30 May 2024 12 UTC (T+216)</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              regions  expected_impact  \\\n",
       "4                        [Myanmar, India, Bangladesh]     1.025611e+06   \n",
       "3                                 [India, Bangladesh]     9.990156e+05   \n",
       "8                        [Myanmar, India, Bangladesh]     9.681755e+05   \n",
       "1                        [Myanmar, India, Bangladesh]     6.830140e+05   \n",
       "11  [Venezuela, Colombia, Nicaragua, Costa Rica, P...     9.418765e+04   \n",
       "15  [Venezuela, Colombia, Nicaragua, Costa Rica, P...     6.879827e+04   \n",
       "13                      [Venezuela, Colombia, Panama]     5.447357e+04   \n",
       "6                                             [Japan]     4.102547e+04   \n",
       "0                                        [Madagascar]     6.703489e+03   \n",
       "2                                             [Japan]     3.346325e+03   \n",
       "17                                         [Suriname]     2.039893e+00   \n",
       "14                                                 []     0.000000e+00   \n",
       "18                                                 []     0.000000e+00   \n",
       "16                                                 []     0.000000e+00   \n",
       "10                                                 []     0.000000e+00   \n",
       "12                                                 []     0.000000e+00   \n",
       "9                                                  []     0.000000e+00   \n",
       "7                                                  []     0.000000e+00   \n",
       "5                                                  []     0.000000e+00   \n",
       "19                                                 []     0.000000e+00   \n",
       "\n",
       "                              date        storm_type  \n",
       "4   Tue 28 May 2024 12 UTC (T+168)    tropical storm  \n",
       "3   Wed 29 May 2024 12 UTC (T+192)    tropical storm  \n",
       "8   Mon 27 May 2024 12 UTC (T+144)    tropical storm  \n",
       "1   Sun 26 May 2024 12 UTC (T+120)    tropical storm  \n",
       "11  Sat 01 Jun 2024 12 UTC (T+264)  tropical cyclone  \n",
       "15  Fri 31 May 2024 12 UTC (T+240)  tropical cyclone  \n",
       "13  Tue 28 May 2024 12 UTC (T+168)  tropical cyclone  \n",
       "6   Fri 31 May 2024 12 UTC (T+240)    tropical storm  \n",
       "0    Sat 25 May 2024 12 UTC (T+96)    tropical storm  \n",
       "2   Sat 01 Jun 2024 12 UTC (T+264)    tropical storm  \n",
       "17  Mon 27 May 2024 12 UTC (T+144)  tropical cyclone  \n",
       "14  Thu 30 May 2024 12 UTC (T+216)  tropical cyclone  \n",
       "18  Wed 29 May 2024 12 UTC (T+192)         hurricane  \n",
       "16   Fri 24 May 2024 12 UTC (T+72)  tropical cyclone  \n",
       "10  Sun 26 May 2024 12 UTC (T+120)  tropical cyclone  \n",
       "12  Wed 29 May 2024 12 UTC (T+192)  tropical cyclone  \n",
       "9    Sat 25 May 2024 12 UTC (T+96)  tropical cyclone  \n",
       "7    Fri 24 May 2024 12 UTC (T+72)    tropical storm  \n",
       "5   Thu 30 May 2024 12 UTC (T+216)    tropical storm  \n",
       "19  Thu 30 May 2024 12 UTC (T+216)         hurricane  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.sort_values('expected_impact', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "950482a2-0c46-40e7-8c59-e4b8e4920a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FROM = 'stormspyder.alerts@gmail.com'\n",
    "TO = [\"jessicakristenr@gmail.com\"]\n",
    "SUBJECT = \"!!! ALERT: TROPICAL STORM APPROACHING INDIA AND BANGLADESH, 600K ESTIMATED IMPACTED\"\n",
    "TEXT = \"This message was sent with Python's smtplib.\"\n",
    "\n",
    "# Prepare actual message\n",
    "message = \"\"\"\\\n",
    "From: %s\n",
    "To: %s\n",
    "Subject: %s\n",
    "\n",
    "%s\n",
    "\"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\n",
    "\n",
    "\n",
    "yag = yagmail.SMTP(FROM, 'kmgy vpdd ifwa ljzi')\n",
    "yag.send(TO, SUBJECT, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737f1b8-2dbb-4464-81a9-6e4b4330c91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
